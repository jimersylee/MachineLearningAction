###基于概率论的分类方法
####朴素贝叶斯
- 使用概率分布进行分类
- 学习朴素贝叶斯分类器
- 解析RSS源数据
- 使用朴素贝叶斯来分析不同地区的态度


####朴素贝叶斯
优点:在数据较少的情况下仍然有效,可以处理多类别问题
缺点:对于输入数据的准备方式较为敏感
使用数据类型:标称型数据


####贝叶斯决策理论的核心思想--即选择具有最高概率的决策


##条件概率

P(A|B)=$$\underline{P(AB)}\\P(B)$$

###使用贝叶斯准则,进行条件与结果的互换计算
已知P(A|B),求P(B|A)

P(B|A)=$$\underline{P(A|B)P(B)}\\P(A)$$


推导
>给定某个点(x,y),那么该点来自$$c_i$$的概率为P($$c_i$$|x,y)

P($$c_i$$|x,y)=$$\underline{P(x,y|c_i)P(c_i)}\\P(x,y)$$

结论
>如果$$P(c_1|x,y)>P(c_2|x,y)$$,那么(x,y)属于$$c_1$$
如果$$P(c_2|x,y)>P(c_1|x,y)$$,那么(x,y)属于$$c_2$$




###使用朴素贝叶斯进行文档分类
朴素贝叶斯是贝叶斯分类器的一个扩展,是用于文档分类的常用算法
朴素贝叶斯的一帮过程
1. 收集数据:可以使用任何方法,本章使用RSS源
2. 准备数据:需要数值型或者布尔型数据
3. 分析数据:有大量特征时,绘制特征作用不大,此时使用直方图效果较好
4. 训练算法:计算不同的独立特征的条件概率
5. 测试算法:计算错误率
6. 使用算法:一个常见的朴素贝叶斯应用是文档分类.可以在任意的分类场景中使用朴素贝叶斯分类器,不一定非要是文本.


假设词汇表有1000个单词,要得到好的概率分布,需要足够的样本,假设样本数为N
>由统计学知,如果每个特征需要N个样本,那么对于x个特征,将需要$$N^x$$个样本

对于1000个特征的词汇表将需要$$N^{1000}$$个样本,可以看到,所需要的样本数会随着特征数目的增大而迅速增长
如果特征之间项目独立,那么样本数就能从$$N^{1000}$$减少到N*1000.所谓独立,指的是**统计学上的独立,即一个特征或者单词出现的可能性与它和其他相邻单词没关系**


####使用Python进行文本分类
1. 准备数据:从文本中构建词向量,详见bayes.py中的 createVocabList setOfWords2Vec
2. 训练算法:从词向量计算概率



















